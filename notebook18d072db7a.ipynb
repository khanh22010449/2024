{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"0ad18b9cce5171a92b1ace78d675cb7cfe7b38ef1dfda11fe1bc29cba1874dd4"}},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9832483,"sourceType":"datasetVersion","datasetId":6030706},{"sourceId":158874,"sourceType":"modelInstanceVersion","modelInstanceId":135035,"modelId":157780}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/khanhtranlong/notebook18d072db7a?scriptVersionId=205752778\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Notes\n\nWe provide this notebook for inference and visualizations. \n\nYou can either load images from a dataloader(see Sec. 1) or from a local path(see Sec. 2).\n\nWelcome to join [IDEA](https://idea.edu.cn/en)([中文网址](https://idea.edu.cn/))!","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/IDEA-Research/DINO.git","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd DINO","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torchvision","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -r requirements.txt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cd models/dino/ops","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python setup.py build install","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python test.py","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cd ..","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cd ..","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cd ..","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os, sys\nimport torch, json\nimport numpy as np\n\nfrom main import build_model_main\nfrom util.slconfig import SLConfig\nfrom datasets import build_dataset\nfrom util.visualizer import COCOVisualizer\nfrom util import box_ops","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 0. Initialize and Load Pre-trained Models","metadata":{}},{"cell_type":"code","source":"model_config_path = \"config/DINO/DINO_4scale.py\" # change the path of the model config file\nmodel_checkpoint_path = \"/kaggle/input/dino/transformers/default/1/checkpoint.pth\" # change the path of the model checkpoint\n# See our Model Zoo section in README.md for more details about our pretrained models.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"args = SLConfig.fromfile(model_config_path) \nargs.device = 'cuda' \nmodel, criterion, postprocessors = build_model_main(args)\ncheckpoint = torch.load(model_checkpoint_path, map_location='gpu')\nmodel.load_state_dict(checkpoint['model'])\n_ = model.eval()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# load coco names\nwith open('util/coco_id2name.json') as f:\n    id2name = json.load(f)\n    id2name = {int(k):v for k,v in id2name.items()}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 1. Visualize images from a dataloader\n## 1.1 Load Datasets","metadata":{}},{"cell_type":"code","source":"args.dataset_file = 'coco'\nargs.coco_path = \"/comp_robot/cv_public_dataset/COCO2017/\" # the path of coco\nargs.fix_size = False\n\ndataset_val = build_dataset(image_set='val', args=args)   ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.2 Get an Example and Visualize it","metadata":{}},{"cell_type":"code","source":"image, targets = dataset_val[0]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# build gt_dict for vis\nbox_label = [id2name[int(item)] for item in targets['labels']]\ngt_dict = {\n    'boxes': targets['boxes'],\n    'image_id': targets['image_id'],\n    'size': targets['size'],\n    'box_label': box_label,\n}\nvslzr = COCOVisualizer()\nvslzr.visualize(image, gt_dict, savedir=None)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.3 Visualize Model Predictions","metadata":{}},{"cell_type":"code","source":"output = model.cuda()(image[None].cuda())\noutput = postprocessors['bbox'](output, torch.Tensor([[1.0, 1.0]]).cuda())[0]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"thershold = 0.3 # set a thershold\n\nscores = output['scores']\nlabels = output['labels']\nboxes = box_ops.box_xyxy_to_cxcywh(output['boxes'])\nselect_mask = scores > thershold","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"box_label = [id2name[int(item)] for item in labels[select_mask]]\npred_dict = {\n    'boxes': boxes[select_mask],\n    'size': targets['size'],\n    'box_label': box_label\n}\nvslzr.visualize(image, pred_dict, savedir=None)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Visualize Custom Images","metadata":{}},{"cell_type":"code","source":"from PIL import Image\nimport datasets.transforms as T","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image = Image.open(\"./figs/idea.jpg\").convert(\"RGB\") # load image","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# transform images\ntransform = T.Compose([\n    T.RandomResize([800], max_size=1333),\n    T.ToTensor(),\n    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\nimage, _ = transform(image, None)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# predict images\noutput = model.cuda()(image[None].cuda())\noutput = postprocessors['bbox'](output, torch.Tensor([[1.0, 1.0]]).cuda())[0]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# visualize outputs\nthershold = 0.3 # set a thershold\n\nvslzr = COCOVisualizer()\n\nscores = output['scores']\nlabels = output['labels']\nboxes = box_ops.box_xyxy_to_cxcywh(output['boxes'])\nselect_mask = scores > thershold\n\nbox_label = [id2name[int(item)] for item in labels[select_mask]]\npred_dict = {\n    'boxes': boxes[select_mask],\n    'size': torch.Tensor([image.shape[1], image.shape[2]]),\n    'box_label': box_label\n}\nvslzr.visualize(image, pred_dict, savedir=None, dpi=100)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}